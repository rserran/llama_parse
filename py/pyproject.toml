[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[dependency-groups]
dev = [
  "pytest>=8.0.0,<9",
  "pytest-xdist>=3.6.1,<4",
  "pytest-asyncio",
  "ipykernel>=6.29.0,<7",
  "pre-commit==3.2.0",
  "autoevals>=0.0.114,<0.0.115",
  "deepdiff>=8.1.1,<9",
  "ipython>=8.12.3,<9",
  "jupyter>=1.1.1,<2",
  "mypy>=1.14.1,<2",
  "pydantic-settings>=2.10.1"
]

[project]
name = "llama-cloud-services"
version = "0.6.63"
description = "Tailored SDK clients for LlamaCloud services."
authors = [{name = "Logan Markewich", email = "logan@runllama.ai"}]
requires-python = ">=3.9,<4.0"
readme = "README.md"
license = "MIT"
dependencies = [
  "llama-index-core>=0.12.0",
  "llama-cloud==0.1.37",
  "pydantic>=2.8,!=2.10",
  "click>=8.1.7,<9",
  "python-dotenv>=1.0.1,<2",
  "eval-type-backport>=0.2.0,<0.3 ; python_version < '3.10'",
  "platformdirs>=4.3.7,<5",
  "tenacity>=8.5.0, <10.0",
  "packaging>=25.0"
]

[project.scripts]
llama-parse = "llama_cloud_services.parse.cli.main:parse"

[tool.hatch.build.targets.sdist]
include = ["llama_cloud_services"]

[tool.hatch.build.targets.wheel]
include = ["llama_cloud_services"]

[tool.mypy]
files = ["llama_cloud_services"]
python_version = "3.10"
